server:
  port: 18080

logging:
  file: canal-kafka-hbase.log
  path: C:\Users\b\Desktop
  level:
    com:
      zgl: INFO
    org:
      springframework:
        web: INFO
      mybaties: ERROR

spring:
  redis:
    host: 192.168.20.90
    port: 6379
    pool:
      max-idle: 100
      min-idle: 1
      max-active: 1000
      max-wait: -1

hbase:
  master: hadoop-master:16000
  zookeeper:
    quorum: hadoop-master,hadoop-slave01,hadoop-slave02
    property:
      clientPort: 2181
  split:
    info: 1,2,3
  #  info: 1,2,3,4,5,6,7,8,9,A,B,C,D,E,F  #表预切分
zookeeper:
  znode:
    parent: /hbase

kafka:
  consumer:
    zookeeper:
      connect: 192.168.10.83:2181,192.168.10.84:2181,192.168.10.85:2181,
    servers: 192.168.10.83:9092,192.168.10.84:9092,192.168.10.85:9092
    enable:
      auto:
        commit: true
    session:
      timeout: 6000
    auto:
      commit:
        interval: 100
      offset:
        reset: latest
    topic: mhd-notice
    group:
      id: mhd-notice
    concurrency: 10
  producer:
    servers: 192.168.10.83:9092,192.168.10.84:9092,192.168.10.85:9092
    retries: 0
    batch:
      size: 4096
    linger: 1
    buffer:
      memory: 40960

elasticsearch:
  cluster:
    nodes: 192.168.10.78:9300,192.168.10.77:9300,192.168.10.79:9300
    name: es-cluster
  client:
    transport:
      sniff: true

